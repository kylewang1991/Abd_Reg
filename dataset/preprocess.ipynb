{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "\n",
    "import dicom2nifti # to convert DICOM files to the NIftI format\n",
    "import nibabel as nib # nibabel to handle nifti files\n",
    "import SimpleITK as sitk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def analyze_images(folder_root, image_path, label_path):\n",
    "    \"\"\"\n",
    "    Analyze the images in the given subfolder and return the statistics as a dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - subfolder_path: str, the path to the subfolder containing the images\n",
    "    - suffix: str, the suffix of the image files (e.g., '_cropped.nii.gz')\n",
    "    \n",
    "    Returns:\n",
    "    - result: dict, the statistics of the images\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(folder_root, image_path)\n",
    "    label_path = os.path.join(folder_root, label_path)\n",
    "\n",
    "    \n",
    "    if os.path.exists(image_path) and os.path.exists(label_path):\n",
    "        # Read the NIfTI files\n",
    "        image = sitk.ReadImage(image_path)\n",
    "        label = sitk.ReadImage(label_path)\n",
    "        \n",
    "        # Get spacing and size\n",
    "        image_spacing = image.GetSpacing()\n",
    "        label_spacing = label.GetSpacing()\n",
    "\n",
    "\n",
    "        # Get orientation\n",
    "        image_orientation = image.GetDirection()\n",
    "        label_orientation = label.GetDirection()\n",
    "\n",
    "        # Calculate the range of pixel values in the patient image\n",
    "        image_array = sitk.GetArrayFromImage(image)\n",
    "        pixel_min = np.min(image_array)\n",
    "        pixel_max = np.max(image_array)\n",
    "        pixel_range = (pixel_min, pixel_max)\n",
    "\n",
    "        # Calculate unique values in liver and vessels images\n",
    "        label_array = sitk.GetArrayFromImage(label)\n",
    "        label_unique_values = np.unique(label_array)\n",
    "        \n",
    "        \n",
    "        image_size = image.GetSize()\n",
    "        label_size = label.GetSize()\n",
    "\n",
    "        # Check if spacing and size are the same\n",
    "        if image_spacing != label_spacing:\n",
    "            raise ValueError(f\"Spacing mismatch in subfolder {image_path}\")\n",
    "        if image_size != label_size:\n",
    "            raise ValueError(f\"Size mismatch in subfolder {image_path}\")\n",
    "        # Check if orientations are the same\n",
    "        # if image_orientation != label_orientation:\n",
    "        #     raise ValueError(f\"Orientation mismatch in subfolder {image_path}\")\n",
    "\n",
    "        # Calculate length\n",
    "        length = tuple(p * s for p, s in zip(image_spacing, image_size))\n",
    "\n",
    "        # Record the results\n",
    "        result = {\n",
    "            'Subfolder': os.path.basename(image_path),\n",
    "            'Spacing': list(image_spacing),\n",
    "            'Size': list(image_size),\n",
    "            'Length': list(length),\n",
    "            'orientation': list(image_orientation),\n",
    "            'label orientation': list(label_orientation),\n",
    "            'Pixel Range': list(pixel_range),\n",
    "            'label Unique Values': list(label_unique_values),\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        raise FileNotFoundError(\"One or more required files are missing.\")\n",
    "    \n",
    "def analyze_and_save_images(root_folder, json_path, excel_filename):\n",
    "    \"\"\"\n",
    "    Traverse all subfolders in folder_root, analyze the images, and save the results to an Excel file.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_root: str, the root folder containing the subfolders with images\n",
    "    - suffix: str, the suffix of the image files (e.g., '.nii.gz')\n",
    "    - excel_filename: str, the name of the output Excel file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"{json_path} does not exist.\")\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for key in ['training', 'valid', 'test']:\n",
    "        for set in ['0', '1']:\n",
    "            for image_label_pair in data[key][set]:\n",
    "                image_path = image_label_pair['image']\n",
    "                label_path = image_label_pair['label']\n",
    "                root_path = os.path.join(root_folder, data[\"root_dir\"])\n",
    "                result = analyze_images(root_path,  image_path, label_path)\n",
    "                results.append(result)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    # Write the results to an Excel file\n",
    "    output_excel_path = os.path.join(\"./\", excel_filename)\n",
    "    df_results.to_excel(output_excel_path, index=False)\n",
    "    print(f\"Results saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./amos_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "root_folder = os.path.join(os.getcwd(), \"..\")\n",
    "json_path = os.path.join(root_folder, 'dataset/amos/amos22_dataset_adjusted.json')\n",
    "excel_filename = 'amos_results.xlsx'\n",
    "analyze_and_save_images(root_folder, json_path, excel_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_all(path_json):\n",
    "    with open(path_json, 'r') as f:\n",
    "        info = json.load(f)\n",
    "\n",
    "    root_dir = info[\"root_dir\"]\n",
    "\n",
    "    for key in [\"training\", \"valid\", \"test\"]:\n",
    "        for fix_move in [\"0\", \"1\"]:\n",
    "            for image_label in info[key][fix_move]:\n",
    "                image = os.path.join(root_dir, image_label[\"image\"])\n",
    "                label = os.path.join(root_dir, image_label[\"label\"])\n",
    "                os.remove(image)\n",
    "                os.remove(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_voxel_spacing(path_json):\n",
    "    with open(path_json, 'r') as f:\n",
    "        info = json.load(f)\n",
    "\n",
    "    root_dir = info[\"root_dir\"]\n",
    "\n",
    "    for key in [\"training\", \"valid\", \"test\"]:\n",
    "        for fix_move in [\"0\", \"1\"]:\n",
    "            for image_label in info[key][fix_move]:\n",
    "                image = os.path.join(root_dir, image_label[\"image\"])\n",
    "                label = os.path.join(root_dir, image_label[\"label\"])\n",
    "\n",
    "                volume = sitk.ReadImage(image) # read and cast to float32\n",
    "                original_spacing = volume.GetSpacing()\n",
    "                original_size = volume.GetSize()\n",
    "                image_data = sitk.GetArrayFromImage(volume)\n",
    "                image_filed = [int(round(osz*ospc)) for osz,ospc in zip(original_size, original_spacing)]\n",
    "                image_spacing = [int(round(i*100)) for i in original_spacing]\n",
    "                print(f\"image_filed: {image_filed} spacing: {image_spacing} size: {original_size} max: {image_data.max()}  min: {image_data.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_volume(input_path, output_path, new_size, new_spacing, min=0, max=800, is_mask=False, filed_clip=(0, 0, 0)):\n",
    "    volume = sitk.ReadImage(input_path, sitk.sitkFloat32) # read and cast to float32\n",
    "\n",
    "    volume_data = sitk.GetArrayFromImage(volume)\n",
    "\n",
    "    if not is_mask:\n",
    "        if max > min:\n",
    "            volume_data = numpy.clip(volume_data, min, max)\n",
    "            volume_data = (volume_data - min)/(max - min)\n",
    "        elif max == min:\n",
    "            max = numpy.max(volume_data)\n",
    "            min = numpy.min(volume_data)\n",
    "            assert( max > min)\n",
    "            volume_data = (volume_data - min)/(max - min)\n",
    "        else :\n",
    "            raise ValueError()\n",
    "\n",
    "\n",
    "\n",
    "    img_range_adjusted = sitk.GetImageFromArray(volume_data)\n",
    "    img_range_adjusted.CopyInformation(volume)\n",
    "\n",
    "    original_spacing = img_range_adjusted.GetSpacing()\n",
    "    original_size = img_range_adjusted.GetSize()\n",
    "    original_origin = img_range_adjusted.GetOrigin()\n",
    "\n",
    "    original_filed = [a*b for a,b in zip(original_spacing, original_size)]\n",
    "    new_filed = [a*b for a,b in zip(new_spacing, new_size)]\n",
    "    offset = [(b- a)/2 for a,b in zip(new_filed, original_filed)]\n",
    "    new_origin = [c + b*a for a,b,c in zip([1, -1, 1], offset, original_origin)]\n",
    "            \n",
    "    moved_origin = [c + b*a for a,b,c in zip(filed_clip, offset, new_origin)]\n",
    "\n",
    "    interpolator =  sitk.sitkNearestNeighbor if is_mask  else sitk.sitkLinear\n",
    "    img_resampled = sitk.Resample(img_range_adjusted, new_size, sitk.Transform(), interpolator,\n",
    "                         moved_origin, new_spacing, img_range_adjusted.GetDirection(), 0,\n",
    "                         img_range_adjusted.GetPixelID())\n",
    "    \n",
    "\n",
    "    \n",
    "    sitk.WriteImage(img_resampled, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_all(path_json):\n",
    "    with open(path_json, 'r') as f:\n",
    "        info = json.load(f)\n",
    "\n",
    "    root_dir = os.path.join(os.getcwd(), \"../\", info[\"root_dir\"])\n",
    "    \n",
    "    for key in [\"training\", \"valid\", \"test\"]:\n",
    "        for fix_move in [\"0\", \"1\"]:\n",
    "            spacing = info[\"voxelSpacing\"][fix_move]\n",
    "            size = info[\"tensorImageShape\"][fix_move]\n",
    "            range_min,range_max = info[\"voxelRange\"][fix_move]\n",
    "            filed_clip = info[\"filedClip\"][fix_move]\n",
    "\n",
    "            for image_label in info[key][fix_move]:\n",
    "                image = os.path.join(root_dir, image_label[\"image\"])\n",
    "                label = os.path.join(root_dir, image_label[\"label\"])\n",
    "\n",
    "                name_image = os.path.basename(image)\n",
    "                dir_name = os.path.dirname(image)\n",
    "                if name_image.split('.')[-2:] == ['nii','gz']:\n",
    "                    name_image_new = name_image.split('.')[0] + \"_adjust.nii.gz\"\n",
    "                    output_image = os.path.join(dir_name , name_image_new)\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "\n",
    "                name_label = os.path.basename(label)\n",
    "                dir_name = os.path.dirname(label)\n",
    "                if name_label.split('.')[-2:] == ['nii','gz']:\n",
    "                    name_label_new = name_label.split('.')[0] + \"_adjust.nii.gz\"\n",
    "                    output_label = os.path.join(dir_name, name_label_new)\n",
    "                else:\n",
    "                    raise ValueError()            \n",
    "\n",
    "                resample_volume(image, output_image, size, spacing, range_min, range_max, filed_clip=filed_clip)\n",
    "                resample_volume(label, output_label, size, spacing, range_min, range_max, is_mask=True, filed_clip=filed_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json(origin_json_path, new_json_path):\n",
    "    with open(origin_json_path, 'r') as f:\n",
    "        info = json.load(f)\n",
    "\n",
    "    root_dir = info[\"root_dir\"]\n",
    "\n",
    "    for key in [\"training\", \"valid\", \"test\"]:\n",
    "        for fix_move in [\"0\", \"1\"]:\n",
    "            for index,image_label in enumerate(info[key][fix_move]):\n",
    "                image = image_label[\"image\"]\n",
    "                label = image_label[\"label\"]\n",
    "\n",
    "                name_image = os.path.basename(image)\n",
    "                dir_name = os.path.dirname(image)\n",
    "                if name_image.split('.')[-2:] == ['nii','gz']:\n",
    "                    name_image_new = name_image.split('.')[0] + \"_adjust.nii.gz\"\n",
    "                    output_image = os.path.join(dir_name , name_image_new)\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "\n",
    "                name_label = os.path.basename(label)\n",
    "                dir_name = os.path.dirname(label)\n",
    "                if name_label.split('.')[-2:] == ['nii','gz']:\n",
    "                    name_label_new = name_label.split('.')[0] + \"_adjust.nii.gz\"\n",
    "                    output_label = os.path.join(dir_name, name_label_new)\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "                \n",
    "                info[key][fix_move][index][\"image\"] = output_image\n",
    "                info[key][fix_move][index][\"label\"] = output_label\n",
    "\n",
    "    with open(new_json_path, \"w\") as outfile:\n",
    "        json.dump(info, outfile, indent=4)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_all(\"../dataset/chaos/chaos_dataset.json\")\n",
    "update_json(\"../dataset/chaos/chaos_dataset.json\", \"../dataset/chaos/chaos_dataset_adjusted.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_all(\"../dataset/amos/amos22_dataset_reorient.json\")\n",
    "update_json(\"../dataset/amos/amos22_dataset_reorient.json\", \"../dataset/amos/amos22_dataset_adjusted.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
